import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

# é…ç½® Key
api_key = "sk-d75143a2504f43089e4c20d2db3a3a52"
os.environ["DASHSCOPE_API_KEY"] = api_key


def build_term_vector_db():
    pdf_path = "æ³•å¾‹æœ¯è¯­å‚è€ƒ.pdf"
    if not os.path.exists(pdf_path):
        print("âŒ æœªæ‰¾åˆ°æ³•å¾‹æœ¯è¯­å‚è€ƒ.pdf")
        return

    print("ğŸš€ æ­£åœ¨å¯¹æœ¯è¯­æ‰‹å†Œè¿›è¡Œå‘é‡åŒ–...")
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    # æ³•å¾‹æœ¯è¯­é€šå¸¸è¾ƒçŸ­ï¼Œåˆ‡ç‰‡å¯ä»¥å°ä¸€ç‚¹ä»¥ä¾¿ç²¾å‡†åŒ¹é…
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    texts = text_splitter.split_documents(documents)

    embeddings = DashScopeEmbeddings(model="text-embedding-v4")
    vector_db = FAISS.from_documents(texts, embeddings)

    # ä¿å­˜åˆ°ç‹¬ç«‹ç›®å½•
    vector_db.save_local("term_faiss_index")
    print("âœ… æœ¯è¯­çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼Œä¿å­˜åœ¨ term_faiss_index æ–‡ä»¶å¤¹ä¸­ã€‚")


if __name__ == "__main__":
    build_term_vector_db()